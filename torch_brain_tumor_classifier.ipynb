{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ppY0E2oBcXNu",
    "outputId": "523f44ab-6260-44fd-8e22-1ec57ddd7605"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XOjZidblq5JL"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V4PuME0qmFvZ"
   },
   "outputs": [],
   "source": [
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        # images\n",
    "        self.X = images\n",
    "        # labels\n",
    "        self.y = labels\n",
    "\n",
    "        # Transformation for converting original image array to an image and then convert it to a tensor\n",
    "        self.transform = transforms.Compose([transforms.ToPILImage(),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        # Transformation for converting original image array to an image, rotate it randomly between -45 degrees and 45 degrees, and then convert it to a tensor\n",
    "        self.transform1 = transforms.Compose([\n",
    "            transforms.ToPILImage(),                                          \n",
    "            transforms.RandomRotation(45),\n",
    "            transforms.ToTensor()                                 \n",
    "        ])\n",
    "\n",
    "        # Transformation for converting original image array to an image, rotate it randomly between -90 degrees and 90 degrees, and then convert it to a tensor\n",
    "        self.transform2 = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomRotation(90),\n",
    "            transforms.ToTensor()                                  \n",
    "        ])\n",
    "\n",
    "        # Transformation for converting original image array to an image, rotate it randomly between -120 degrees and 120 degrees, and then convert it to a tensor\n",
    "        self.transform3 = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomRotation(120),\n",
    "            transforms.ToTensor()                                  \n",
    "        ])\n",
    "\n",
    "        # Transformation for converting original image array to an image, rotate it randomly between -180 degrees and 180 degrees, and then convert it to a tensor\n",
    "        self.transform4 = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomRotation(180),\n",
    "            transforms.ToTensor()                                \n",
    "        ])\n",
    "\n",
    "        # Transformation for converting original image array to an image, rotate it randomly between -270 degrees and 270 degrees, and then convert it to a tensor\n",
    "        self.transform5 = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomRotation(270),\n",
    "            transforms.ToTensor()                                \n",
    "        ])\n",
    "\n",
    "        # Transformation for converting original image array to an image, rotate it randomly between -300 degrees and 300 degrees, and then convert it to a tensor\n",
    "        self.transform6 = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomRotation(300),\n",
    "            transforms.ToTensor()                               \n",
    "        ])\n",
    "\n",
    "        # Transformation for converting original image array to an image, rotate it randomly between -330 degrees and 330 degrees, and then convert it to a tensor\n",
    "        self.transform7 = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomRotation(330),\n",
    "            transforms.ToTensor()                                 \n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        # return length of image samples\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # perform transformations on one instance of X\n",
    "        # Original image as a tensor\n",
    "        data = self.transform(self.X[idx])\n",
    "\n",
    "        # Augmented image at 45 degrees as a tensor\n",
    "        aug45 = self.transform1(self.X[idx])\n",
    "\n",
    "        # Augmented image at 90 degrees as a tensor\n",
    "        aug90 = self.transform2(self.X[idx])\n",
    "\n",
    "        # Augmented image at 120 degrees as a tensor\n",
    "        aug120 = self.transform3(self.X[idx])\n",
    "\n",
    "        # Augmented image at 180 degrees as a tensor\n",
    "        aug180 = self.transform4(self.X[idx])\n",
    "\n",
    "        # Augmented image at 270 degrees as a tensor\n",
    "        aug270 = self.transform5(self.X[idx])\n",
    "\n",
    "        # Augmented image at 300 degrees as a tensor\n",
    "        aug300 = self.transform6(self.X[idx])\n",
    "\n",
    "        # Augmented image at 330 degrees as a tensor\n",
    "        aug330 = self.transform7(self.X[idx])      \n",
    "\n",
    "        # store the transformed images in a list\n",
    "        new_batch = [data, aug45, aug90, aug120, aug180, aug270, aug300, aug330]\n",
    "\n",
    "        # one-hot encode the labels\n",
    "        labels = torch.zeros(4, dtype=torch.float32)\n",
    "        labels[int(self.y[idx])] = 1.0\n",
    "\n",
    "        new_labels = [labels, labels, labels, labels, labels, labels, labels, labels]\n",
    "\n",
    "        # 8 augmented images and corresponding labels per sample will be returned\n",
    "        return (torch.stack(new_labels), torch.stack(new_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "trcS9hq8q7Dq"
   },
   "outputs": [],
   "source": [
    "training_data = pickle.load(open(r'C:\\Users\\Pranjwal Bageikari\\Types_Brain_Tumor\\new_dataset\\training_data.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hY6k--StlVAC"
   },
   "outputs": [],
   "source": [
    "Xt = []\n",
    "yt = []\n",
    "features = None\n",
    "labels = None\n",
    "label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9gQx6_RtlwfE"
   },
   "outputs": [],
   "source": [
    "for features,labels in training_data:\n",
    "    Xt.append(features)\n",
    "    yt.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxT6Znuul5Kq"
   },
   "outputs": [],
   "source": [
    "# 70 % training, 15% validating, 15% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xt, yt, test_size=0.3, shuffle=True)  # 70% training, 30% testing\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, shuffle=True)  # split testing set into 50% validation , 50% testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "34qYiYRlJoXH"
   },
   "outputs": [],
   "source": [
    "Xt = None\n",
    "yt = None\n",
    "features = None\n",
    "labels = None\n",
    "label = None\n",
    "training_data = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnTKHLR5mCeI"
   },
   "outputs": [],
   "source": [
    "train_set = BrainTumorDataset(X_train, y_train)\n",
    "valid_set = BrainTumorDataset(X_valid, y_valid)\n",
    "test_set = BrainTumorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "MEL7oQ4Y8NIe",
    "outputId": "b4d33819-b7f1-4b5a-ce44-d7aa9c9d9b0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 4289\n",
      "Number of validation samples: 919\n",
      "Number of testing samples: 920\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training samples: {len(X_train)}\")\n",
    "print(f\"Number of validation samples: {len(X_valid)}\")\n",
    "print(f\"Number of testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "8PJu7hjEi0Ij",
    "outputId": "b9cb23ac-8182-4b4b-cd7f-d7b93670b615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of augmented training samples: 34312\n",
      "Number of augmented validation samples: 7352\n",
      "Number of augmented testing samples: 7360\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of augmented training samples: {len(X_train) * 8}\")\n",
    "print(f\"Number of augmented validation samples: {len(X_valid)* 8}\")\n",
    "print(f\"Number of augmented testing samples: {len(X_test)* 8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-5Eil06jrRUT"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Use the same batch size for training, validation, and testing\n",
    "batch_size = 4\n",
    "\n",
    "train_gen = DataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=2)\n",
    "valid_gen = DataLoader(valid_set, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=2)\n",
    "test_gen = DataLoader(test_set, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ka_a8OAPtNHY"
   },
   "outputs": [],
   "source": [
    "device_name = \"cuda:0:\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Lq3_lCEttAJk",
    "outputId": "feb12130-9d1d-4c44-d546-6327f266745a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pranjwal Bageikari\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Pranjwal Bageikari\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    (1): SELU()\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    (4): SELU()\n",
      "    (5): Dropout(p=0.4, inplace=False)\n",
      "    (6): Linear(in_features=2048, out_features=4, bias=True)\n",
      "    (7): LogSigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate transfer learning model\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Set all parameters as trainable\n",
    "for param in resnet_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Get input size of the fully connected (fc) layer\n",
    "n_inputs = resnet_model.fc.in_features\n",
    "\n",
    "# Redefine fc layer / top layer / head for our classification problem\n",
    "resnet_model.fc = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 2048),\n",
    "    nn.SELU(),\n",
    "    nn.Dropout(p=0.4),\n",
    "    nn.Linear(2048, 2048),\n",
    "    nn.SELU(),\n",
    "    nn.Dropout(p=0.4),\n",
    "    nn.Linear(2048, 4),  # Adjust to the number of classes in your specific problem\n",
    "    nn.LogSigmoid()\n",
    ")\n",
    "\n",
    "# Set all parameters of the model as trainable\n",
    "for name, child in resnet_model.named_children():\n",
    "    for name2, params in child.named_parameters():\n",
    "        params.requires_grad = True\n",
    "\n",
    "# Set model to run on GPU or CPU based on availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet_model.to(device)\n",
    "\n",
    "# Print the transfer learning NN model's architecture\n",
    "print(resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cokrpXp3ud8_"
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "# if GPU is available set loss function to use GPU\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(resnet_model.parameters(), momentum=0.9, lr=3e-4)\n",
    "\n",
    "# number of training iterations\n",
    "epochs = 30\n",
    "\n",
    "# empty lists to store losses and accuracies\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MnUksQpFNxNK"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename=r'C:\\Users\\Pranjwal Bageikari\\Types_Brain_Tumor\\bt_resnet50_ckpt_v2.pth.tar'):\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# set training start time\n",
    "start_time = time.time()\n",
    "\n",
    "# set best_prec loss value as 2 for checkpoint threshold\n",
    "best_prec1 = 2\n",
    "\n",
    "# empty batch variables\n",
    "b = None\n",
    "train_b = None\n",
    "test_b = None\n",
    "# resnet_model = resnet_model.to('cpu')\n",
    "\n",
    "# start training\n",
    "for i in range(epochs):\n",
    "    # empty training correct and test correct counter as 0 during every iteration\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    print(i)\n",
    "    torch.cuda.empty_cache()\n",
    "    # set epoch's starting time\n",
    "    e_start = time.time()\n",
    "\n",
    "    # train in batches\n",
    "    # ...\n",
    "\n",
    "    # train in batches\n",
    "    accumulation_steps = 4\n",
    "    count_next = 0\n",
    "    with torch.no_grad():\n",
    "        for b, (y, X) in enumerate(train_gen):\n",
    "            # set label as cuda if device is cuda\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            count_next = count_next + 1\n",
    "            print(count_next)\n",
    "\n",
    "            # forward pass image sample\n",
    "            with torch.no_grad():\n",
    "                y_pred = resnet_model(X.view(-1, 3, 512, 512))\n",
    "\n",
    "            loss = criterion(y_pred.float(), torch.argmax(y.view(-1, 4), dim=1).long())\n",
    "            predicted = torch.argmax(y_pred, dim=1).data\n",
    "            batch_corr = (predicted == torch.argmax(y.view(-1, 4), dim=1)).sum()\n",
    "            trn_corr += batch_corr\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        # set epoch's end time\n",
    "    e_end = time.time()\n",
    "    # print training metrics\n",
    "    print(f'Epoch {(i+1)} Batch {(b+1)*4}\\nAccuracy: {trn_corr.item()*100/(4*8*b):2.2f} %  Loss: {loss.item():2.4f}  Duration: {((e_end-e_start)/60):.2f} minutes') # 4 images per batch * 8 augmentations per image * batch length\n",
    "\n",
    "    # some metrics storage for visualization\n",
    "    train_b = b\n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "\n",
    "    X, y = None, None\n",
    "\n",
    "    # validate using validation generator\n",
    "    # do not perform any gradient updates while validation\n",
    "    # ...\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss_sum = 0.0\n",
    "        tst_corr = 0  # Reset tst_corr for validation\n",
    "\n",
    "        for b, (y, X) in enumerate(valid_gen):\n",
    "            # set label as cuda if device is cuda\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # forward pass image\n",
    "            y_val = resnet_model(X.view(-1, 3, 512, 512))\n",
    "\n",
    "            # Calculate validation loss using dynamic shapes\n",
    "            loss = criterion(y_val.float(), torch.argmax(y.view(-1, 4), dim=1).long())\n",
    "\n",
    "            val_loss_sum += loss.item()\n",
    "\n",
    "            # get argmax of predicted tensor, which is our label\n",
    "            predicted = torch.argmax(y_val, dim=1).data\n",
    "            # increment test correct with correctly predicted labels per batch\n",
    "            tst_corr += (predicted == torch.argmax(y.view(-1, 4), dim=1)).sum()\n",
    "\n",
    "\n",
    "    # calculate average validation loss\n",
    "    val_loss_avg = val_loss_sum / (b + 1)\n",
    "\n",
    "    # print validation metrics\n",
    "    print(f'Validation Accuracy {tst_corr.item()*100/(4*8*(b+1)):2.2f} Validation Loss: {val_loss_avg:2.4f}\\n')\n",
    "\n",
    "\n",
    "    # if current validation loss is less than previous iteration's validatin loss create and save a checkpoint\n",
    "    is_best = loss < best_prec1\n",
    "    best_prec1 = min(loss, best_prec1)\n",
    "    save_checkpoint({\n",
    "            'epoch': i + 1,\n",
    "            'state_dict': resnet_model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "        }, is_best)\n",
    "\n",
    "\n",
    "    # some metrics storage for visualization\n",
    "    test_b  = b\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "\n",
    "\n",
    "# set total training's end time\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "# print training summary\n",
    "print(\"\\nTraining Duration {:.2f} minutes\".format(end_time/60))\n",
    "print(\"GPU memory used : {} kb\".format(torch.cuda.memory_allocated()))\n",
    "print(\"GPU memory cached : {} kb\".format(torch.cuda.memory_cached()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U5hiXkZkwW-W"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K4yzcJMmwPnY"
   },
   "outputs": [],
   "source": [
    "torch.save(resnet_model.state_dict(), r'C:\\Users\\Pranjwal Bageikari\\Types_Brain_Tumorbt_resnet50_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4w0EuNLQvmNV",
    "outputId": "685ce068-21f1-4419-c278-555cde282b40"
   },
   "outputs": [],
   "source": [
    "print(f'Validation accuracy: {test_correct[-1].item()*100/(test_b*8*4):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "TttSopdFvtr0",
    "outputId": "6bc80323-bb7c-4a70-eae5-544ed8c363fb"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.title('Loss Metrics')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "YKzECNFZvx9u",
    "outputId": "7a995797-5511-4b7d-8227-ea9af093cc18"
   },
   "outputs": [],
   "source": [
    "plt.plot([t/171 for t in train_correct], label='Training accuracy')\n",
    "plt.plot([t/36 for t in test_correct], label='Validation accuracy')\n",
    "plt.title('Accuracy Metrics')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SsVJuIwych21"
   },
   "outputs": [],
   "source": [
    "# resnet_model.load_state_dict(torch.load('/content/drive/My Drive/bt_resnet_torch.pt'))\n",
    "train_gen = None\n",
    "valid_gen = None\n",
    "train_set = None\n",
    "valid_set = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WZJ7w9ztv1pb",
    "outputId": "e59c6347-59f8-42e8-aff4-c95e2567f495"
   },
   "source": [
    "# set training start time\n",
    "start_time = time.time()\n",
    "\n",
    "# set best_prec loss value as 2 for checkpoint threshold\n",
    "best_prec1 = 2\n",
    "\n",
    "# empty batch variables\n",
    "b = None\n",
    "train_b = None\n",
    "test_b = None\n",
    "# resnet_model = resnet_model.to('cpu')\n",
    "\n",
    "# start training\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    e_start = time.time()\n",
    "    count_next=0\n",
    "    for b, (y, X) in enumerate(train_gen):\n",
    "      with torch.no_grad():\n",
    "        y_pred = resnet_model(X.view(-1, 3, 512, 512))\n",
    "\n",
    "      count_next = count_next +1\n",
    "      print(count_next)\n",
    "\n",
    "      loss = criterion(y_pred.float(), torch.argmax(y.view(32, 4), dim=1).long())\n",
    "\n",
    "      predicted = torch.argmax(y_pred, dim=1).data\n",
    "      batch_corr = (predicted == torch.argmax(y.view(32, 4), dim=1)).sum()\n",
    "      trn_corr += batch_corr\n",
    "      optimizer.zero_grad()\n",
    "      optimizer.step()\n",
    "    e_end = time.time()\n",
    "    print(f'Epoch {(i+1)} Batch {(b+1)*4}\\nAccuracy: {trn_corr.item()*100/(4*8*b):2.2f} %  Loss: {loss.item():2.4f}  Duration: {((e_end-e_start)/60):.2f} minutes') # 4 images per batch * 8 augmentations per image * batch length\n",
    "\n",
    "    train_b = b\n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "    X, y = None, None\n",
    "    with torch.no_grad():\n",
    "      val_loss_sum = 0.0\n",
    "      for b, (y, X) in enumerate(valid_gen):\n",
    "          X, y = X.to(device), y.to(device)\n",
    "\n",
    "          y_val = resnet_model(X.view(-1, 3, 512, 512))\n",
    "          loss = criterion(y_val.float(), torch.argmax(y.view(32, 4), dim=1).long())\n",
    "          val_loss_sum += loss.item()\n",
    "          predicted = torch.argmax(y_val, dim=1).data\n",
    "          tst_corr += (predicted == torch.argmax(y.view(32, 4), dim=1)).sum()\n",
    "\n",
    "      val_loss_avg = val_loss_sum / (b + 1)\n",
    "\n",
    "      print(f'Validation Accuracy {tst_corr.item()*100/(4*8*(b+1)):2.2f} Validation Loss: {val_loss_avg:2.4f}\\n')\n",
    "\n",
    "      is_best = loss < best_prec1\n",
    "      best_prec1 = min(loss, best_prec1)\n",
    "      save_checkpoint({\n",
    "              'epoch': i + 1,\n",
    "              'state_dict': resnet_model.state_dict(),\n",
    "              'best_prec1': best_prec1,\n",
    "          }, is_best)\n",
    "\n",
    "      test_b  = b\n",
    "      test_losses.append(loss)\n",
    "      test_correct.append(tst_corr)\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print(\"\\nTraining Duration {:.2f} minutes\".format(end_time/60))\n",
    "print(\"GPU memory used : {} kb\".format(torch.cuda.memory_allocated()))\n",
    "print(\"GPU memory cached : {} kb\".format(torch.cuda.memory_cached()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HJm2yjzHbLlP",
    "outputId": "7b227ca6-3d4d-44cd-a030-a0e0cc8d744e"
   },
   "outputs": [],
   "source": [
    "print(f'Test accuracy: {test_corr[-1].item()*100/(460*8):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDRv0IhThKhP"
   },
   "outputs": [],
   "source": [
    "labels = torch.stack(labels)\n",
    "pred = torch.stack(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7BsASCMlL2_z"
   },
   "outputs": [],
   "source": [
    "LABELS = ['Meningioma', 'Glioma', 'Pitutary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "colab_type": "code",
    "id": "3cfoG8Q0gMKZ",
    "outputId": "95a96f4c-bf40-4efd-a0f2-31d5606c657a"
   },
   "outputs": [],
   "source": [
    "arr = confusion_matrix(pred.view(-1).cpu(), labels.view(-1).cpu())\n",
    "df_cm = pd.DataFrame(arr, LABELS, LABELS)\n",
    "plt.figure(figsize = (9,6))\n",
    "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='viridis')\n",
    "plt.xlabel(\"Prediction\")\n",
    "plt.ylabel(\"Target\")4rkt76\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "id": "MNWrpWVXL_pQ",
    "outputId": "4dd25c3d-45e9-4c8c-cf56-11c58a41cecd"
   },
   "outputs": [],
   "source": [
    "print(f\"Clasification Report\\n\\n{classification_report(pred.view(-1).cpu(), labels.view(-1).cpu())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "WXiYK3JxMC3F",
    "outputId": "f4288b40-ded1-491d-b242-6c052b3dcbc6"
   },
   "outputs": [],
   "source": [
    "print(f\"Jaccard Index\\n\\n{round(jaccard_similarity_score(pred.view(-1).cpu(), labels.view(-1).cpu()), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "brain_tumor_classifier_resnet_torch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
