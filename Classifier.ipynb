{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HA7brFG2HjY4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "import torch.autograd.profiler\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, jaccard_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1r0JFJG4IQul"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "o_Pmt3lrIQxG"
   },
   "outputs": [],
   "source": [
    "class BrainTumorDataset(Dataset):\n",
    "  def __init__(self, images, labels):\n",
    "    # images\n",
    "    self.X = images\n",
    "    # labels\n",
    "    self.y = labels\n",
    "\n",
    "    # Transformation for converting original image array to an image and then convert it to a tensor\n",
    "    self.transform = transforms.Compose([transforms.ToPILImage(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Transformation for converting original image array to an image, rotate it randomly between -45 degrees and 45 degrees, and then convert it to a tensor\n",
    "    self.transform1 = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Transformation for converting original image array to an image, rotate it randomly between -90 degrees and 90 degrees, and then convert it to a tensor\n",
    "    self.transform2 = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(90),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Transformation for converting original image array to an image, rotate it randomly between -120 degrees and 120 degrees, and then convert it to a tensor\n",
    "    self.transform3 = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(120),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Transformation for converting original image array to an image, rotate it randomly between -180 degrees and 180 degrees, and then convert it to a tensor\n",
    "    self.transform4 = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(180),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Transformation for converting original image array to an image, rotate it randomly between -270 degrees and 270 degrees, and then convert it to a tensor\n",
    "    self.transform5 = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(270),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Transformation for converting original image array to an image, rotate it randomly between -300 degrees and 300 degrees, and then convert it to a tensor\n",
    "    self.transform6 = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(300),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Transformation for converting original image array to an image, rotate it randomly between -330 degrees and 330 degrees, and then convert it to a tensor\n",
    "    self.transform7 = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(330),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "  def __len__(self):\n",
    "    # return length of image samples\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # perform transformations on one instance of X\n",
    "    # Original image as a tensor\n",
    "    data = self.transform(self.X[idx])\n",
    "\n",
    "    # Augmented image at 45 degrees as a tensor\n",
    "    aug45 = self.transform1(self.X[idx])\n",
    "\n",
    "    # Augmented image at 90 degrees as a tensor\n",
    "    aug90 = self.transform2(self.X[idx])\n",
    "\n",
    "    # Augmented image at 120 degrees as a tensor\n",
    "    aug120 = self.transform3(self.X[idx])\n",
    "\n",
    "    # Augmented image at 180 degrees as a tensor\n",
    "    aug180 = self.transform4(self.X[idx])\n",
    "\n",
    "    # Augmented image at 270 degrees as a tensor\n",
    "    aug270 = self.transform5(self.X[idx])\n",
    "\n",
    "    # Augmented image at 300 degrees as a tensor\n",
    "    aug300 = self.transform6(self.X[idx])\n",
    "\n",
    "    # Augmented image at 330 degrees as a tensor\n",
    "    aug330 = self.transform7(self.X[idx])\n",
    "\n",
    "    # store the transformed images in a list\n",
    "    new_batch = [data, aug45, aug90, aug120, aug180, aug270, aug300, aug330]\n",
    "\n",
    "    # one-hot encode the labels\n",
    "    labels = torch.zeros(4, dtype=torch.float32)\n",
    "    labels[int(self.y[idx])] = 1.0\n",
    "\n",
    "    new_labels = [labels, labels, labels, labels, labels, labels, labels, labels]\n",
    "\n",
    "    # 8 augmented images and corresponding labels per sample will be returned\n",
    "    return (torch.stack(new_labels), torch.stack(new_batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Ttk2wlifIQzn"
   },
   "outputs": [],
   "source": [
    "training_data = pickle.load(open(r'C:\\Users\\Pranjwal Bageikari\\Types_Brain_Tumor\\new_dataset\\training_data.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6cUXkEiCIQ2S"
   },
   "outputs": [],
   "source": [
    "Xt = []\n",
    "yt = []\n",
    "features = None\n",
    "labels = None\n",
    "label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wdnjJSArIQ41"
   },
   "outputs": [],
   "source": [
    "\n",
    "for features,labels in training_data:\n",
    "  Xt.append(features)\n",
    "  yt.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7FE2ahgrIQ7Q"
   },
   "outputs": [],
   "source": [
    "# 70 % training, 15% validating, 15% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xt, yt, test_size=0.3, shuffle=True)  # 70% training, 30% testing\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, shuffle=True)  # split testing set into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "zsSzoZRwIQ-B"
   },
   "outputs": [],
   "source": [
    "Xt = None\n",
    "yt = None\n",
    "features = None\n",
    "labels = None\n",
    "label = None\n",
    "training_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "uQVfwcrcIRAp"
   },
   "outputs": [],
   "source": [
    "train_set = BrainTumorDataset(X_train, y_train)\n",
    "valid_set = BrainTumorDataset(X_valid, y_valid)\n",
    "test_set = BrainTumorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_wBJwG_IRDF",
    "outputId": "b0c98b78-7ffe-4ee1-ee55-b3977e64fc57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 2144\n",
      "Number of validation samples: 460\n",
      "Number of testing samples: 460\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training samples: {len(X_train)}\")\n",
    "print(f\"Number of validation samples: {len(X_valid)}\")\n",
    "print(f\"Number of testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Wj-siTTIRF1",
    "outputId": "01beb560-aeca-478a-e0bc-7bce6d23f40c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of augmented training samples: 17152\n",
      "Number of augmented validation samples: 3680\n",
      "Number of augmented testing samples: 3680\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of augmented training samples: {len(X_train) * 8}\")\n",
    "print(f\"Number of augmented validation samples: {len(X_valid)* 8}\")\n",
    "print(f\"Number of augmented testing samples: {len(X_test)* 8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "myqGEWmOIRIj"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Use the same batch size for training, validation, and testing\n",
    "batch_size = 4\n",
    "\n",
    "train_gen = DataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=1)\n",
    "valid_gen = DataLoader(valid_set, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=1)\n",
    "test_gen = DataLoader(test_set, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r0V0lfNqoi-5",
    "outputId": "ba271927-a269-4656-e3f6-6a7d7b720c60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536\n",
      "115\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "leng= len(train_gen)\n",
    "print(leng)\n",
    "leng_1= len(valid_gen)\n",
    "print(leng_1)\n",
    "leng_2= len(test_gen)\n",
    "print(leng_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "97BiLbtDIRLD"
   },
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pIz2ka-IRNg",
    "outputId": "62deb84a-c19e-440b-dfc5-db3cb2159ec1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pranjwal Bageikari\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Pranjwal Bageikari\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    (1): SELU()\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    (4): SELU()\n",
      "    (5): Dropout(p=0.4, inplace=False)\n",
      "    (6): Linear(in_features=2048, out_features=4, bias=True)\n",
      "    (7): LogSigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate transfer learning model\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Set all parameters as trainable\n",
    "for param in resnet_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Get input size of the fully connected (fc) layer\n",
    "n_inputs = resnet_model.fc.in_features\n",
    "\n",
    "# Redefine fc layer / top layer / head for our classification problem\n",
    "resnet_model.fc = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 2048),\n",
    "    nn.SELU(),\n",
    "    nn.Dropout(p=0.4),\n",
    "    nn.Linear(2048, 2048),\n",
    "    nn.SELU(),\n",
    "    nn.Dropout(p=0.4),\n",
    "    nn.Linear(2048, 4),  # Adjust to the number of classes in your specific problem\n",
    "    nn.LogSigmoid()\n",
    ")\n",
    "\n",
    "# Set all parameters of the model as trainable\n",
    "for name, child in resnet_model.named_children():\n",
    "    for name2, params in child.named_parameters():\n",
    "        params.requires_grad = True\n",
    "\n",
    "# Set model to run on GPU or CPU based on availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet_model.to(device)\n",
    "\n",
    "# Print the transfer learning NN model's architecture\n",
    "print(resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "74DmyKbLIRQ4"
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "# if GPU is available set loss function to use GPU\n",
    "resnet_model = resnet_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(resnet_model.parameters(), momentum=0.9, lr=3e-4)\n",
    "\n",
    "# number of training iterations\n",
    "epochs = 30\n",
    "\n",
    "# empty lists to store losses and accuracies\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "wA-tt7b7JR61"
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_checkpoint(state, is_best, filename='/content/drive/My Drive/bt_resnet50_ckpt_v2.pth.tar'):\n",
    "    torch.save(state, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UyVKK_GxKYHv",
    "outputId": "d6c1b9d4-2f4b-4e8b-df1a-6acead75a284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# set training start time\n",
    "start_time = time.time()\n",
    "\n",
    "# set best_prec loss value as 2 for checkpoint threshold\n",
    "best_prec1 = 2\n",
    "\n",
    "# empty batch variables\n",
    "b = None\n",
    "train_b = None\n",
    "test_b = None\n",
    "# resnet_model = resnet_model.to('cpu')\n",
    "\n",
    "# start training\n",
    "for i in range(epochs):\n",
    "    # empty training correct and test correct counter as 0 during every iteration\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    print(i)\n",
    "    torch.cuda.empty_cache()\n",
    "    # set epoch's starting time\n",
    "    e_start = time.time()\n",
    "    accumulation_steps = 4\n",
    "    count_next = 0\n",
    "    with torch.no_grad():\n",
    "        for b, (y, X) in enumerate(train_gen):\n",
    "            # set label as cuda if device is cuda\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            count_next = count_next + 1\n",
    "            print(count_next)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                y_pred = resnet_model(X.view(-1, 3, 512, 512))\n",
    "\n",
    "            loss = criterion(y_pred.float(), torch.argmax(y.view(-1, 4), dim=1).long())\n",
    "            predicted = torch.argmax(y_pred, dim=1).data\n",
    "            batch_corr = (predicted == torch.argmax(y.view(-1, 4), dim=1)).sum()\n",
    "            trn_corr += batch_corr\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        # set epoch's end time\n",
    "    e_end = time.time()\n",
    "    # print training metrics\n",
    "    print(f'Epoch {(i+1)} Batch {(b+1)*4}\\nAccuracy: {trn_corr.item()*100/(4*8*b):2.2f} %  Loss: {loss.item():2.4f}  Duration: {((e_end-e_start)/60):.2f} minutes') # 4 images per batch * 8 augmentations per image * batch length\n",
    "\n",
    "    # some metrics storage for visualization\n",
    "    train_b = b\n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "\n",
    "    X, y = None, None\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss_sum = 0.0\n",
    "        tst_corr = 0  # Reset tst_corr for validation\n",
    "\n",
    "        for b, (y, X) in enumerate(valid_gen):\n",
    "            # set label as cuda if device is cuda\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # forward pass image\n",
    "            y_val = resnet_model(X.view(-1, 3, 512, 512))\n",
    "\n",
    "            # Calculate validation loss using dynamic shapes\n",
    "            loss = criterion(y_val.float(), torch.argmax(y.view(-1, 4), dim=1).long())\n",
    "\n",
    "            val_loss_sum += loss.item()\n",
    "\n",
    "            # get argmax of predicted tensor, which is our label\n",
    "            predicted = torch.argmax(y_val, dim=1).data\n",
    "            # increment test correct with correctly predicted labels per batch\n",
    "            tst_corr += (predicted == torch.argmax(y.view(-1, 4), dim=1)).sum()\n",
    "\n",
    "\n",
    "    # calculate average validation loss\n",
    "    val_loss_avg = val_loss_sum / (b + 1)\n",
    "\n",
    "    # print validation metrics\n",
    "    print(f'Validation Accuracy {tst_corr.item()*100/(4*8*(b+1)):2.2f} Validation Loss: {val_loss_avg:2.4f}\\n')\n",
    "\n",
    "\n",
    "    # if current validation loss is less than previous iteration's validatin loss create and save a checkpoint\n",
    "    is_best = loss < best_prec1\n",
    "    best_prec1 = min(loss, best_prec1)\n",
    "    save_checkpoint({\n",
    "            'epoch': i + 1,\n",
    "            'state_dict': resnet_model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "        }, is_best)\n",
    "\n",
    "\n",
    "    # some metrics storage for visualization\n",
    "    test_b  = b\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "\n",
    "\n",
    "# set total training's end time\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "# print training summary\n",
    "print(\"\\nTraining Duration {:.2f} minutes\".format(end_time/60))\n",
    "print(\"GPU memory used : {} kb\".format(torch.cuda.memory_allocated()))\n",
    "print(\"GPU memory cached : {} kb\".format(torch.cuda.memory_cached()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05mYRQG2JSUI"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bS2YFasRJSXx"
   },
   "outputs": [],
   "source": [
    "torch.save(resnet_model.state_dict(), '/content/drive/My Drive/bt_resnet50_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aMtvZlAJg8Y"
   },
   "outputs": [],
   "source": [
    "print(f'Validation accuracy: {test_correct[-1].item()*100/(test_b*8*4):.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QumbascaJg-u"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.title('Loss Metrics')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G6IpplXKJhCP"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot([t/171 for t in train_correct], label='Training accuracy')\n",
    "plt.plot([t/36 for t in test_correct], label='Validation accuracy')\n",
    "plt.title('Accuracy Metrics')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VntaE6XeJoWS"
   },
   "outputs": [],
   "source": [
    "\n",
    "# resnet_model.load_state_dict(torch.load('/content/drive/My Drive/bt_resnet_torch.pt'))\n",
    "train_gen = None\n",
    "valid_gen = None\n",
    "train_set = None\n",
    "valid_set = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHUHinjhJoYX"
   },
   "outputs": [],
   "source": [
    "# set model to evaluation mode\n",
    "resnet_model.eval()\n",
    "\n",
    "# perform no gradient updates\n",
    "with torch.no_grad():\n",
    "    # soem metrics storage for visualization and analysis\n",
    "    correct = 0\n",
    "    test_loss = []\n",
    "    test_corr = []\n",
    "    labels = []\n",
    "    pred = []\n",
    "    # perform test set evaluation batch wise\n",
    "    for (y, X) in test_gen:\n",
    "        # set label to use CUDA if available\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # append original labels\n",
    "        labels.append(torch.argmax(y.view(10 * 8, 4), dim=1).data)\n",
    "\n",
    "        # perform forward pass\n",
    "        y_val = resnet_model(X.view(-1, 3, 512, 512))\n",
    "\n",
    "        # get argmax of predicted values, which is our label\n",
    "        predicted = torch.argmax(y_val, dim=1).data\n",
    "        # append predicted label\n",
    "        pred.append(predicted)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(y_val.float(), torch.argmax(y.view(10 * 8, 4), dim=1).long())\n",
    "\n",
    "        # increment correct with correcly predicted labels per batch\n",
    "        correct += (predicted == torch.argmax(y.view(10 * 8, 4), dim=1)).sum()\n",
    "\n",
    "        # append correct samples labels and losses\n",
    "        test_corr.append(correct)\n",
    "        test_loss.append(loss)\n",
    "\n",
    "print(f\"Test Loss: {test_loss[-1].item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wp2eleUKJoan"
   },
   "outputs": [],
   "source": [
    "print(f'Test accuracy: {test_corr[-1].item()*100/(460*8):.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zne7HetsJoeA"
   },
   "outputs": [],
   "source": [
    "\n",
    "labels = torch.stack(labels)\n",
    "pred = torch.stack(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1vJK6mMJyTi"
   },
   "outputs": [],
   "source": [
    "LABELS = ['Meningioma', 'Glioma', 'Pitutary']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpRrM6rkJyXG"
   },
   "outputs": [],
   "source": [
    "\n",
    "arr = confusion_matrix(pred.view(-1).cpu(), labels.view(-1).cpu())\n",
    "df_cm = pd.DataFrame(arr, LABELS, LABELS)\n",
    "plt.figure(figsize = (9,6))\n",
    "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='viridis')\n",
    "plt.xlabel(\"Prediction\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iK16i2U9J3dA"
   },
   "outputs": [],
   "source": [
    "print(f\"Clasification Report\\n\\n{classification_report(pred.view(-1).cpu(), labels.view(-1).cpu())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEvEogOvJ3fm"
   },
   "outputs": [],
   "source": [
    "print(f\"Jaccard Index\\n\\n{round(jaccard_similarity_score(pred.view(-1).cpu(), labels.view(-1).cpu()), 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZuFPNZkJ3i8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
